{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from typing import TypedDict, Tuple, Set, Dict, List\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSS_COLORS_PATH = \"colourrgbs.json\"\n",
    "IMAGES_FOLDER_PATH = \"../holden_scrape/wallpapers/full/\"\n",
    "MODEL_PATH = \"yolo11x.pt\"\n",
    "TAGS_OUPUT_FILE = \"tags.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('colourrgbs.json', 'r') as f:\n",
    "    # taken from https://www.rapidtables.com/web/color/RGB_Color.html\n",
    "    CSS_COLORS: Dict[str, Tuple[int, int, int]] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectedColors(TypedDict):\n",
    "    main_color_name: str\n",
    "    main_color_rgb: Tuple[int,int,int]\n",
    "    other_colors_names: Set[str]\n",
    "\n",
    "class ImageTags(TypedDict):\n",
    "    image_path: str\n",
    "    objects: List[str]\n",
    "    repeating_pattern: bool\n",
    "    colors: DetectedColors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11x.pt')  # you can use 'yolov8s.pt' or larger models for better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(model, image_path, confidence_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Detect objects in an image and return tags with confidence scores\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        confidence_threshold: Minimum confidence score to consider a detection\n",
    "        \n",
    "    Returns:\n",
    "        List of tuples containing (class_name, confidence_score)\n",
    "    \"\"\"    \n",
    "    # Run inference on GPU\n",
    "    results = model(image_path, device='cuda')\n",
    "    \n",
    "    # Extract detected objects\n",
    "    detections = []\n",
    "    \n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            confidence = float(box.conf[0])\n",
    "            if confidence >= confidence_threshold:\n",
    "                class_id = int(box.cls[0])\n",
    "                class_name = model.names[class_id]\n",
    "                detections.append((class_name, confidence))\n",
    "    \n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_repeating_pattern(img_path, fft_thresh=5.0, autocorr_thresh=0.3):\n",
    "    \"\"\"\n",
    "    Detects repeating patterns using FFT spectrum analysis and autocorrelation\n",
    "    Args:\n",
    "        img_path: Path to input image\n",
    "        fft_thresh: Threshold for FFT magnitude variance (empirical)\n",
    "        autocorr_thresh: Threshold for autocorrelation peaks (0-1)\n",
    "    Returns:\n",
    "        bool: True if repeating pattern detected\n",
    "    \"\"\"\n",
    "    # Read and preprocess image\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (256, 256))  # Standardize size\n",
    "    \n",
    "    # FFT Analysis\n",
    "    fft = np.fft.fft2(img)\n",
    "    fft_shift = np.fft.fftshift(fft)\n",
    "    # Revised FFT analysis\n",
    "    magnitude = np.abs(fft_shift)\n",
    "    fft_score = np.std(magnitude) / (np.mean(magnitude) + 1e-6)\n",
    "        \n",
    "    # Improved autocorrelation analysis\n",
    "    autocorr = np.fft.ifft2(np.abs(fft)**2).real\n",
    "    autocorr = cv2.normalize(autocorr, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # Revised autocorrelation with peak validation\n",
    "    center = autocorr[64:192, 64:192]\n",
    "    peak_value = np.percentile(center, 99.9)\n",
    "    peak_count = np.sum(center > 0.8*peak_value)  # Count significant peaks\n",
    "    \n",
    "    \n",
    "    # Decision logic\n",
    "    return (\n",
    "        (fft_score > fft_thresh) and \n",
    "        (peak_value > autocorr_thresh) and\n",
    "        (peak_count > 1) and  # Require multiple peaks\n",
    "        (np.mean(magnitude) > np.min(magnitude))  # Reject flat spectra\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified color matching section\n",
    "def closest_color(rgb_array: np.ndarray) -> str:\n",
    "    \"\"\"Find closest CSS color using numpy vector operations\"\"\"\n",
    "    css_colors = np.array(list(CSS_COLORS.values()))\n",
    "    color_names = list(CSS_COLORS.keys())\n",
    "    distances = np.linalg.norm(css_colors - rgb_array, axis=1)\n",
    "    return color_names[np.argmin(distances)]\n",
    "\n",
    "def detect_colors(image_path: str, num_colors: int = 15) -> DetectedColors:\n",
    "    \"\"\"\n",
    "    Detect dominant colors in an image using K-Means clustering\n",
    "    Args:\n",
    "        image_path: Path to input image\n",
    "        num_colors: Number of dominant colors to detect\n",
    "    Returns:\n",
    "        DetectedColors dictionary with main color and other prominent colors\n",
    "    \"\"\"\n",
    "    # Load image and convert to RGB\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resize for faster processing and convert to float32\n",
    "    img = cv2.resize(img, (200, 200), interpolation=cv2.INTER_AREA)\n",
    "    pixels = img.reshape(-1, 3).astype(np.float32)\n",
    "    \n",
    "    # K-Means clustering to find dominant colors\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, 0.1)\n",
    "    _, labels, centers = cv2.kmeans(\n",
    "        pixels, num_colors, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS\n",
    "    )\n",
    "    \n",
    "    # Get color frequencies and sort by prevalence\n",
    "    label_counts = Counter(labels.flatten())\n",
    "    sorted_colors = sorted(centers, key=lambda c: -label_counts[np.where(centers == c)[0][0]])\n",
    "    # Convert to numpy arrays before color matching\n",
    "    main_rgb = sorted_colors[0].tolist()\n",
    "    other_rgbs = sorted_colors[1:]\n",
    "\n",
    "    \n",
    "    return {\n",
    "        'main_color_name': closest_color(main_rgb),\n",
    "        'main_color_rgb': list(round(i) for i in main_rgb),\n",
    "        'other_colors_names': list(closest_color(c) for c in other_rgbs)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_tags = []\n",
    "for idx, img_path in enumerate(glob(IMAGES_FOLDER_PATH+\"*.jpg\")):\n",
    "    if idx % 20 == 0:\n",
    "        print(f\"=>Processing image {idx}\")\n",
    "    tags = {\n",
    "        \"image_path\": img_path,\n",
    "        \"objects\": [img_score[0] for img_score in detect_objects(model, img_path)],\n",
    "        \"repeating_pattern\": True if has_repeating_pattern(img_path) else False,\n",
    "        \"colors\": detect_colors(img_path)\n",
    "    }\n",
    "    images_tags.append(tags)\n",
    "    with open(TAGS_OUPUT_FILE, \"w\") as f:\n",
    "        json.dump(images_tags, f)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
